{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 22:37:58.931025: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-09 22:37:59.021475: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-09 22:37:59.064703: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-09 22:37:59.074657: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-09 22:37:59.133344: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-09 22:37:59.869274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 12.5.1\n",
      "cuDNN version: 9\n",
      "OrderedDict([('cpu_compiler', '/usr/lib/llvm-18/bin/clang'), ('cuda_compute_capabilities', ['sm_60', 'sm_70', 'sm_80', 'sm_89', 'compute_90']), ('cuda_version', '12.5.1'), ('cudnn_version', '9'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False)])\n",
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"CUDA version:\", tf.sysconfig.get_build_info()[\"cuda_version\"])\n",
    "print(\"cuDNN version:\", tf.sysconfig.get_build_info()[\"cudnn_version\"])\n",
    "print(tf.sysconfig.get_build_info())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and TensorFlow is using it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731172081.086247  197817 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731172081.159378  197817 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731172081.161926  197817 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available and TensorFlow is using it.\")\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled for GPU.\n"
     ]
    }
   ],
   "source": [
    "# Enable memory growth for the GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPU.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GPU and CPU devices\n",
    "gpu_device = \"/device:GPU:0\"  # Adjust the index if you have multiple GPUs\n",
    "cpu_device = \"/device:CPU:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.load('embeddings_1.npy')\n",
    "X_2 = np.load('embeddings_2.npy')\n",
    "X = np.concatenate((X, X_2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dimensions: (198982, 1024)\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(X)           # Number of rows\n",
    "num_columns = len(X[0])     # Number of columns (assuming non-empty and rectangular)\n",
    "print(\"X dimensions:\", (num_rows, num_columns)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731172081.737748  197817 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731172081.740922  197817 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731172081.743210  197817 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731172081.917245  197817 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731172081.919010  197817 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731172081.920594  197817 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-09 22:38:01.924315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2679 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y: (198982, 1400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 22:38:04.614220: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Read label data from files (assuming you have already defined this part)\n",
    "label_data = []\n",
    "file_names = ['icd_codes_1.txt', 'icd_codes_2.txt']  # Update with actual filenames\n",
    "for file_name in file_names:\n",
    "    with open(file_name, 'r') as file:\n",
    "        label_data.extend(line.strip() for line in file if line.strip())\n",
    "\n",
    "# Step 2: Create a set of unique ICD-10 codes for efficient lookup\n",
    "unique_codes = set()\n",
    "for labels in label_data:\n",
    "    unique_codes.update(labels.split(\";\"))\n",
    "unique_codes = sorted(unique_codes)  # Convert to a sorted list at the end\n",
    "\n",
    "# Step 3: Initialize the StringLookup layer\n",
    "lookup_layer = tf.keras.layers.StringLookup(vocabulary=unique_codes, output_mode=\"multi_hot\", mask_token=None,num_oov_indices=0)\n",
    "\n",
    "# Step 4: Create a tf.data.Dataset to handle large data efficiently\n",
    "label_data_ds = tf.data.Dataset.from_tensor_slices(label_data)\n",
    "\n",
    "with tf.device(cpu_device):\n",
    "    # Step 5: Define a function to encode each label set\n",
    "    def encode_labels(labels):\n",
    "        \n",
    "        multi_hot = lookup_layer(tf.strings.split(labels, sep=\";\"))\n",
    "        return tf.cast(multi_hot, dtype=tf.int16)  # Reducing the precision here\n",
    "\n",
    "    # Step 6: Map encoding function over the dataset and batch it\n",
    "    # Batch processing reduces memory usage\n",
    "    multi_hot_labels_ds = label_data_ds.map(encode_labels, num_parallel_calls=tf.data.AUTOTUNE).batch(1000)\n",
    "\n",
    "    # Step 7: Concatenate all batches to get the final `y` tensor\n",
    "    y = tf.concat(list(multi_hot_labels_ds), axis=0)\n",
    "\n",
    "# Ensure the correct shape of `y`\n",
    "print(\"Shape of y:\", y.shape)  # Should output: (200000, 1400)\n",
    "\n",
    "y = y.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (198982, 1024)\n",
      "Shape of y: (198982, 1400)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (159185, 1024)\n",
      "y_train shape: (159185, 1400)\n",
      "X_val shape: (39797, 1024)\n",
      "y_val shape: (39797, 1400)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class MicroF2Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='micro_f2_score', beta=2, **kwargs):\n",
    "        super(MicroF2Score, self).__init__(name=name, **kwargs)\n",
    "        self.beta = beta\n",
    "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.fn = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Threshold y_pred to get binary predictions\n",
    "        y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "        \n",
    "        # Cast y_true to float32 to ensure compatibility\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        # Calculate true positives, false positives, and false negatives\n",
    "        true_positive = tf.reduce_sum(y_true * y_pred)\n",
    "        false_positive = tf.reduce_sum(y_pred * (1 - y_true))\n",
    "        false_negative = tf.reduce_sum((1 - y_pred) * y_true)\n",
    "\n",
    "        # Update the corresponding weights\n",
    "        self.tp.assign_add(true_positive)\n",
    "        self.fp.assign_add(false_positive)\n",
    "        self.fn.assign_add(false_negative)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n",
    "        recall = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n",
    "        f_beta = (1 + self.beta**2) * (precision * recall) / (self.beta**2 * precision + recall + tf.keras.backend.epsilon())\n",
    "        return f_beta\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.tp.assign(0)\n",
    "        self.fp.assign(0)\n",
    "        self.fn.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, LayerNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import he_uniform, he_normal, glorot_uniform, glorot_normal\n",
    "from sklearn.metrics import fbeta_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define the model using the Sequential API with added complexity and batch normalization\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Specify the input shape directly\n",
    "    Dense(1024, activation='relu', kernel_initializer=he_normal),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation='relu', kernel_initializer=he_normal),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu', kernel_initializer=he_normal),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1400, activation='sigmoid')  # Sigmoid activation for multi-label classification\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer and binary crossentropy loss\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "\n",
    "with tf.device(gpu_device):\n",
    "    # Compile model with Adam optimizer and custom focal loss\n",
    "    optimizer = Adam(learning_rate=0.0003)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[MicroF2Score()])\n",
    "\n",
    "    # Callbacks for early stopping and learning rate reduction\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, mode='min')\n",
    "    model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, mode='min')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X, y, \n",
    "                        batch_size=32,  # Optimized batch size\n",
    "                        epochs=100,\n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[early_stopping, model_checkpoint, lr_scheduler],\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
